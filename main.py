import feedparser
import telebot
import os
import re
import time
import hashlib
import urllib.parse
import psycopg2
from urllib.parse import urlparse as url_parse
from apscheduler.schedulers.background import BackgroundScheduler
from flask import Flask, request
import logging
from urllib.parse import parse_qs, urlunparse, urlencode
from googletrans import Translator
import deepl
import html
import sys
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –¢–æ–∫–µ–Ω –∏ –∫–∞–Ω–∞–ª –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
TOKEN = os.getenv('TELEGRAM_TOKEN')
CHANNEL = os.getenv('TELEGRAM_CHANNEL')
DEEPL_API_KEY = os.getenv('DEEPL_API_KEY')
DATABASE_URL = os.getenv('DATABASE_URL')  # –î–ª—è PostgreSQL

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
if not TOKEN or not CHANNEL or not DATABASE_URL:
    logger.error("–ù–µ –∑–∞–¥–∞–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è!")
    sys.exit(1)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–æ–≤
translator = Translator()
deepl_translator = None
if DEEPL_API_KEY:
    try:
        deepl_translator = deepl.Translator(DEEPL_API_KEY)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ DeepL: {e}")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç—Ä–µ–∫–∏–Ω–≥–æ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
TRACKING_PARAMS = {
    'utm_source', 'utm_medium', 'utm_campaign', 'utm_term', 'utm_content',
    'ref', 'referral', 'source', 'fbclid', 'gclid', 'yclid', '_openstat',
    'campaign', 'mc_cid', 'mc_eid', 'session_id', 'icid', 'trk', 'trk_contact',
    'utm_referrer', 'utm_reader', 'utm_place', 'fb_action_ids', 'fb_action_types',
    'fb_ref', 'ga_source', 'ga_medium', 'ga_term', 'ga_content', 'ga_campaign',
    'pk_source', 'pk_medium', 'pk_campaign'
}

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö PostgreSQL
def get_db_connection():
    try:
        conn = psycopg2.connect(DATABASE_URL, sslmode='require')
        return conn
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        raise

# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ
def init_db():
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS sent_news (
                normalized_link TEXT,
                original_link TEXT,
                title TEXT,
                title_hash TEXT,
                pubdate TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                PRIMARY KEY (normalized_link, title_hash)
            )
        ''')
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_title_hash 
            ON sent_news(title_hash)
        ''')
        conn.commit()
        logger.info("–¢–∞–±–ª–∏—Ü–∞ sent_news —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞ –∏–ª–∏ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {e}")
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã
        try:
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS sent_news (
                    normalized_link TEXT,
                    original_link TEXT,
                    title TEXT,
                    title_hash TEXT,
                    pubdate TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    PRIMARY KEY (normalized_link, title_hash)
                )
            ''')
            conn.commit()
            logger.info("–¢–∞–±–ª–∏—Ü–∞ —Å–æ–∑–¥–∞–Ω–∞ –ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏")
        except Exception as e2:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ç–∞–±–ª–∏—Ü—ã: {e2}")
            sys.exit(1)
    finally:
        if conn:
            conn.close()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
init_db()

bot = telebot.TeleBot(TOKEN)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ö–µ—à–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞
def get_title_hash(title):
    """–í—ã—á–∏—Å–ª—è–µ—Ç SHA-256 —Ö–µ—à –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
    clean_title = title.strip().lower()
    return hashlib.sha256(clean_title.encode('utf-8')).hexdigest()

def translate_text(text, src='auto', dest='ru'):
    """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤"""
    if not text.strip():
        return text
        
    try:
        # –ü—Ä–æ–±—É–µ–º DeepL –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        if deepl_translator:
            result = deepl_translator.translate_text(text, target_lang=dest)
            return result.text
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Google Translate –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
        translation = translator.translate(text, src=src, dest=dest)
        return translation.text
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
        return text  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏

def normalize_url(url):
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL —Å —É–¥–∞–ª–µ–Ω–∏–µ–º —Ç—Ä–µ–∫–∏–Ω–≥–æ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
    try:
        parsed = url_parse(url)
        
        # –ü—Ä–∏–≤–æ–¥–∏–º –¥–æ–º–µ–Ω –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ —É–¥–∞–ª—è–µ–º www
        netloc = parsed.netloc.lower()
        if netloc.startswith('www.'):
            netloc = netloc[4:]
        
        # –£–¥–∞–ª—è–µ–º —è–∫–æ—Ä—å
        parsed = parsed._replace(fragment="", netloc=netloc)
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–ø—Ä–æ—Å–∞
        if parsed.query:
            query_params = parse_qs(parsed.query, keep_blank_values=True)
            filtered_params = {}
            
            for key, values in query_params.items():
                # –ü—Ä–∏–≤–æ–¥–∏–º –∫–ª—é—á –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                key_lower = key.lower()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ—Ç—Ä–µ–∫–∏–Ω–≥–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                if key_lower not in TRACKING_PARAMS:
                    filtered_params[key] = values
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏—è
            sorted_params = sorted(filtered_params.items(), key=lambda x: x[0])
            new_query = urlencode(sorted_params, doseq=True)
            parsed = parsed._replace(query=new_query)
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Å–ª—ç—à–∏ –≤ –ø—É—Ç–∏
        path = re.sub(r'/{2,}', '/', parsed.path)
        parsed = parsed._replace(path=path)
        
        return urlunparse(parsed)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ URL {url}: {e}")
        return url

def is_new(link, title):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–æ–≤–æ—Å—Ç—å –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É URL –∏ —Ö–µ—à—É –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
    normalized = normalize_url(link)
    title_hash = get_title_hash(title)
    
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute('''
            SELECT 1 FROM sent_news 
            WHERE normalized_link = %s AND title_hash = %s
        ''', (normalized, title_hash))
        return cursor.fetchone() is None
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏: {e}")
        return True  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —Å—á–∏—Ç–∞–µ–º –Ω–æ–≤–æ—Å—Ç—å –Ω–æ–≤–æ–π
    finally:
        if conn:
            conn.close()

def save_news(link, title):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–æ–≤–æ—Å—Ç—å —Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º URL –∏ —Ö–µ—à–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
    try:
        normalized = normalize_url(link)
        title_hash = get_title_hash(title)
        
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO sent_news 
            (normalized_link, original_link, title, title_hash)
            VALUES (%s, %s, %s, %s)
            ON CONFLICT (normalized_link, title_hash) DO NOTHING
        ''', (normalized, link, title, title_hash))
        conn.commit()
        logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –Ω–æ–≤–æ—Å—Ç—å: {title}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –±–∞–∑—É: {e}")
    finally:
        if conn:
            conn.close()

def clean_html(raw_html):
    """–£–¥–∞–ª—è–µ—Ç HTML-—Ç–µ–≥–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    if not raw_html:
        return ""
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', raw_html)
    return html.unescape(cleantext)

def contains_topic(content):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ –Ω–æ–≤–æ—Å—Ç—å –∫ –Ω—É–∂–Ω–æ–π —Ç–µ–º–∞—Ç–∏–∫–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π"""
    # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –æ—Ç HTML-—Ç–µ–≥–æ–≤
    clean_content = clean_html(content).lower()
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö
    patterns = [
        # –†—É—Å—Å–∫–∏–π
        r'\b—Å—É—Ä—Ä–æ–≥–∞—Ç–Ω\w*\b', r'\b—ç–∫–æ\b', r'\b–≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ã–µ\b', 
        r'\b–≤–ø—Ä\b', r'\b–¥–æ–Ω–æ—Ä—Å—Ç–≤–æ –æ–æ—Ü–∏—Ç–æ–≤\b', r'\b–¥–æ–Ω–æ—Ä—Å—Ç–≤–æ —Å–ø–µ—Ä–º—ã\b',
        r'\b—Å—É—Ä–º–∞–º–∞\b', r'\b—Å—É—Ä—Ä–æ–≥–∞—Ç–Ω–æ–π –º–∞—Ç–µ—Ä–∏\b', r'\b—Ä–µ–ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω\w*\b',
        r'\b–±–µ—Å–ø–ª–æ–¥–∏–µ\b', r'\b–æ–ø–ª–æ–¥–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ in vitro\b',
        
        # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π
        r'\bsurrogacy\b', r'\bivf\b', r'\bassisted reproductive technology\b', 
        r'\bart\b', r'\begg donation\b', r'\bsperm donation\b',
        r'\bfertility treatment\b', r'\bin vitro fertilization\b',
        r'\bembryo transfer\b', r'\bsurrogate mother\b', r'\bfertility clinic\b',
        r'\breproductive medicine\b', r'\bgestational carrier\b',
        
        # –ò—Å–ø–∞–Ω—Å–∫–∏–π
        r'\bmaternidad subrogada\b', r'\bfiv\b', r'\bdonaci√≥n de √≥vulos\b', 
        r'\bdonaci√≥n de esperma\b', r'\bgestaci√≥n subrogada\b',
        r'\bfertilidad\b', r'\breproducci√≥n asistida\b',
        
        # –§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π
        r'\bm√®re porteuse\b', r'\bpma\b', r'\bdon d‚Äôovocytes\b', 
        r'\bdon de sperme\b', r'\bprocr√©ation m√©dicalement assist√©e\b',
        r'\bgestation pour autrui\b', r'\bfertilit√©\b',
        
        # –ù–µ–º–µ—Ü–∫–∏–π
        r'\bleihmutterschaft\b', r'\bk√ºnstliche befruchtung\b', r'\beizellspende\b',
        r'\bsamenspende\b', r'\breproduktionsmedizin\b', r'\bfruchtbarkeit\b',
        r'\bin-vitro-fertilisation\b',
        
        # –ò—Ç–∞–ª—å—è–Ω—Å–∫–∏–π
        r'\bmaternit√† surrogata\b', r'\bgravidanza surrogata\b', r'\bdonazione di ovociti\b',
        r'\bdonazione di sperma\b', r'\bprocreazione medicalmente assistita\b',
        r'\bfertilita\b', r'\bfivet\b',
        
        # –ö–∏—Ç–∞–π—Å–∫–∏–π
        r'\b‰ª£Â≠ï\b', r'\bËØïÁÆ°Â©¥ÂÑø\b', r'\bÂçµÂ≠êÊçêËµ†\b', r'\bÁ≤æÂ≠êÊçêËµ†\b',  # –ò–µ—Ä–æ–≥–ª–∏—Ñ—ã
        r'\bd√†iy√πn\b', r'\bsh√¨gu«én yƒ´ng√©r\b', r'\blu«énz«ê juƒÅnz√®ng\b',  # –ü–∏–Ω—å–∏–Ω—å
        r'\bjƒ´ngz«ê juƒÅnz√®ng\b', r'\bËæÖÂä©ÁîüÊÆñ\b'
    ]
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –≤—Å–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
    for pattern in patterns:
        if re.search(pattern, clean_content, re.IGNORECASE):
            return True
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä
    if re.search(r'\bart\b', clean_content, re.IGNORECASE):
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è ART (—á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å "–∏—Å–∫—É—Å—Å—Ç–≤–æ")
        context_keywords = [
            '—Ä–µ–ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω', 'fertility', 'fiv', '–æ–ø–ª–æ–¥–æ—Ç–≤–æ—Ä–µ–Ω', 'reproduction',
            'reproducci√≥n', 'reprodu√ß√£o', 'fortplantning', '–≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ'
        ]
        if any(kw in clean_content for kw in context_keywords):
            return True
    
    return False

# –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã—Ö RSS-–ª–µ–Ω—Ç
RSS_FEEDS = [
    # –†—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–µ
    'https://lenta.ru/rss/news',
    'https://rssexport.rbc.ru/rbcnews/news/30/full.rss',
    'https://tass.ru/rss/v2.xml',
    'https://rssexport.rbc.ru/rbcnews/news/30/full.rss',
    
    # –ê–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ
    'https://www.fertilitynetworkuk.org/feed/',
    'https://www.news-medical.net/tag/feed/ivf.aspx',
    'https://www.technologyreview.com/feed/',
    'https://www.sciencedaily.com/rss/health_medicine/fertility.xml',
    'https://www.nih.gov/news-events/news-releases/rss.xml',
    'https://www.bbc.com/news/health/rss.xml',
    'https://www.reutersagency.com/feed/?best-topics=health',
    'http://rss.cnn.com/rss/edition_health.rss',
    'https://www.theguardian.com/science/health/rss',
    'https://rss.dw.com/rdf/rss-en-health',
    
    # –§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–µ
    'https://www.lemonde.fr/sante/rss_full.xml',
    'https://www.lefigaro.fr/rss/figaro_sante.xml',
    'https://www.liberation.fr/arc/outboundfeeds/rss/section/sante/?outputType=xml',
    
    # –ò—Å–ø–∞–Ω—Å–∫–∏–µ
    'https://www.elmundo.es/rss/salud.xml',
    'https://www.abc.es/rss/feeds/abc_Salud.xml',
    'https://elpais.com/sociedad/salud/rss',
    
    # –ù–µ–º–µ—Ü–∫–∏–µ
    'https://www.spiegel.de/gesundheit/index.rss',
    'https://www.faz.net/rss/aktuell/gesundheit/',
    'https://www.sueddeutsche.de/gesundheit/rss',
    
    # –ò—Ç–∞–ª—å—è–Ω—Å–∫–∏–µ
    'https://www.corriere.it/salute/rss',
    'https://www.repubblica.it/salute/rss',
    'https://www.lastampa.it/rss/salute',
    
    # –ö–∏—Ç–∞–π—Å–∫–∏–µ
    'http://www.xinhuanet.com/english/rss/healthrss.xml',
    'https://www.chinanews.com/rss/health.shtml',
    'https://www.scmp.com/rss/90/feed',  # Health section
    
    # –Ø–ø–æ–Ω—Å–∫–∏–µ
    'https://www.nikkei.com/rss/news/cate/health.html',
    
    # –ö–æ—Ä–µ–π—Å–∫–∏–µ
    'https://www.koreabiomed.com/rss/news',
    
    # –ü–æ—Ä—Ç—É–≥–∞–ª—å—Å–∫–∏–µ (–ë—Ä–∞–∑–∏–ª–∏—è)
    'https://g1.globo.com/rss/g1/saude/',
    
    # –ê—Ä–∞–±—Å–∫–∏–µ
    'https://www.aljazeera.net/xml/rss/all.xml',
    
    # –ò–Ω–¥–∏–π—Å–∫–∏–µ
    'https://www.thehindu.com/sci-tech/health/rss'
]

def check_feeds():
    start_time = time.time()
    logger.info('–ù–∞—á–∞–ª–æ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π...')
    new_count = 0
    duplicate_count = 0
    irrelevant_count = 0
    
    for url in RSS_FEEDS:
        try:
            feed = feedparser.parse(url)
            if not feed.entries:
                logger.warning(f"–ù–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –≤ —Ñ–∏–¥–µ: {url}")
                continue
                
            logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∏–¥–∞: {url} ({len(feed.entries)} –Ω–æ–≤–æ—Å—Ç–µ–π)")
            
            for entry in feed.entries:
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
                    if time.time() - start_time > 240:  # 4 –º–∏–Ω—É—Ç—ã
                        logger.warning("–ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑-–∑–∞ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏")
                        break
                        
                    link = entry.get('link', '')
                    title = clean_html(entry.get('title', ''))
                    summary = clean_html(entry.get('summary', entry.get('description', '')))
                    
                    if not link or not title:
                        continue
                    
                    # –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                    full_content = f"{title} {summary}".lower()
                    
                    # –£—Å–∏–ª–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–º–∞—Ç–∏–∫–∏
                    if not contains_topic(full_content):
                        irrelevant_count += 1
                        logger.debug(f"–ù–æ–≤–æ—Å—Ç—å –Ω–µ –ø–æ —Ç–µ–º–µ: {title}")
                        continue
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
                    if is_new(link, title):
                        # –ó–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
                        time.sleep(0.2)
                        
                        send_news(title, link)
                        save_news(link, title)
                        new_count += 1
                    else:
                        duplicate_count += 1
                        logger.info(f"–î—É–±–ª–∏–∫–∞—Ç –Ω–æ–≤–æ—Å—Ç–∏: {title} | URL: {normalize_url(link)}")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –Ω–æ–≤–æ—Å—Ç–∏: {e}")
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ RSS {url}: {e}")
            time.sleep(2)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
    
    # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("DELETE FROM sent_news WHERE pubdate < NOW() - INTERVAL '30 days'")
        deleted_count = cursor.rowcount
        conn.commit()
        logger.info(f"–û—á–∏—â–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π: {deleted_count}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –ë–î: {e}")
    finally:
        if conn:
            conn.close()
    
    elapsed = time.time() - start_time
    logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed:.2f} —Å–µ–∫. –ù–æ–≤—ã–µ: {new_count}, –¥—É–±–ª–∏–∫–∞—Ç—ã: {duplicate_count}, –Ω–µ –ø–æ —Ç–µ–º–µ: {irrelevant_count}")

def send_news(title, link):
    try:
        original_title = title
        translated = False
        
        # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —è–∑—ã–∫
        try:
            detected_lang = translator.detect(title).lang
            if detected_lang != 'ru':
                # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —è–∑—ã–∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∏ –Ω–µ —Ä—É—Å—Å–∫–∏–π
                ru_title = translate_text(title, src=detected_lang, dest='ru')
                if ru_title != title:
                    title = f"{ru_title}\n({original_title})"
                    translated = True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è–∑—ã–∫–∞: {e}")
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –≥–∏–ø–µ—Ä—Å—Å—ã–ª–∫–æ–π –≤–º–µ—Å—Ç–æ –ø–æ–ª–Ω–æ–≥–æ URL
        message = f"üî¨ *{title}*\n\n[–ò—Å—Ç–æ—á–Ω–∏–∫]({link})\n\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ö—ç—à—Ç–µ–≥–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —è–∑—ã–∫–∞
        hashtags = "#–í–†–¢ #–≠–ö–û #–°—É—Ä—Ä–æ–≥–∞—Ç–Ω–æ–µ–ú–∞—Ç–µ—Ä–∏–Ω—Å—Ç–≤–æ"
        if translated:
            hashtags += " #–ü–µ—Ä–µ–≤–æ–¥"
        
        message += hashtags
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Markdown
        bot.send_message(
            CHANNEL, 
            message, 
            parse_mode='Markdown',
            disable_web_page_preview=True
        )
        logger.info(f"–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–æ—Å—Ç—å: {original_title}")
    except Exception as e:
        logger.error(f'–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}')

# –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º 5 –º–∏–Ω—É—Ç
scheduler = BackgroundScheduler()
scheduler.add_job(
    check_feeds,
    'interval',
    minutes=5,
    max_instances=1,
    next_run_time=datetime.now()  # –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å—Ä–∞–∑—É –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
)
scheduler.start()

# Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = Flask(__name__)

@app.route('/')
def home():
    return "–ë–æ—Ç –∞–∫—Ç–∏–≤–µ–Ω! –°–ª–µ–¥—É—é—â–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ 5 –º–∏–Ω—É—Ç"

@app.route('/check-now')
def manual_check():
    """–†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏"""
    try:
        check_feeds()
        return "–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞–ø—É—â–µ–Ω–∞!"
    except Exception as e:
        return f"–û—à–∏–±–∫–∞: {str(e)}", 500

@app.route('/health')
def health_check():
    return "OK", 200

if __name__ == '__main__':
    # –ó–∞–ø—É—Å–∫–∞–µ–º Flask
    port = int(os.environ.get('PORT', 10000))
    logger.info(f"–ó–∞–ø—É—Å–∫ Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –ø–æ—Ä—Ç—É {port}")
    app.run(host='0.0.0.0', port=port)
